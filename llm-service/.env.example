# LLM Provider Configuration (FR-007, FR-008)
# Switch providers by changing LLM_PROVIDER value - no code changes needed
LLM_PROVIDER=openai  # Options: "openai" or "ollama"
LLM_MODEL=gpt-4o     # For OpenAI: gpt-4o, gpt-4-turbo, etc. For Ollama: llama3.2, qwen2.5:7b, etc.

# OpenAI Configuration (when LLM_PROVIDER=openai)
OPENAI_API_KEY=your-openai-api-key-here

# Ollama Configuration (when LLM_PROVIDER=ollama)
# Ollama must be running locally with the specified model pulled
OLLAMA_BASE_URL=http://localhost:11434/v1

# Supabase Configuration
# Get these values from: supabase status (after running supabase start)
SUPABASE_URL=http://127.0.0.1:54321
SUPABASE_ANON_KEY=your-anon-key-from-supabase-status
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key-from-supabase-status
